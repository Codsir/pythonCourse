{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599380519170",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 对Titanic数据进行清洗，建模并对乘客生存进行预测。使用之前介绍过的10种模型中的至少2种（包括TPOT）\n",
    "-  https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "训练数据行列数: (891, 12) ; 测试数据行列数: (418, 11)\n-------------------- 训练集数据探索 --------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\nPassengerId    891 non-null int64\nSurvived       891 non-null int64\nPclass         891 non-null int64\nName           891 non-null object\nSex            891 non-null object\nAge            714 non-null float64\nSibSp          891 non-null int64\nParch          891 non-null int64\nTicket         891 non-null object\nFare           891 non-null float64\nCabin          204 non-null object\nEmbarked       889 non-null object\ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n---------------------------------------- ----------------------------------------\n       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   891.000000  891.000000  891.000000  714.000000  891.000000   \nmean    446.000000    0.383838    2.308642   29.699118    0.523008   \nstd     257.353842    0.486592    0.836071   14.526497    1.102743   \nmin       1.000000    0.000000    1.000000    0.420000    0.000000   \n25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n75%     668.500000    1.000000    3.000000   38.000000    1.000000   \nmax     891.000000    1.000000    3.000000   80.000000    8.000000   \n\n            Parch        Fare  \ncount  891.000000  891.000000  \nmean     0.381594   32.204208  \nstd      0.806057   49.693429  \nmin      0.000000    0.000000  \n25%      0.000000    7.910400  \n50%      0.000000   14.454200  \n75%      0.000000   31.000000  \nmax      6.000000  512.329200  \n-------------------- 测试集数据探索 --------------------\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 418 entries, 0 to 417\nData columns (total 11 columns):\nPassengerId    418 non-null int64\nPclass         418 non-null int64\nName           418 non-null object\nSex            418 non-null object\nAge            332 non-null float64\nSibSp          418 non-null int64\nParch          418 non-null int64\nTicket         418 non-null object\nFare           417 non-null float64\nCabin          91 non-null object\nEmbarked       418 non-null object\ndtypes: float64(2), int64(4), object(5)\nmemory usage: 36.0+ KB\n---------------------------------------- ----------------------------------------\n       PassengerId      Pclass         Age       SibSp       Parch        Fare\ncount   418.000000  418.000000  332.000000  418.000000  418.000000  417.000000\nmean   1100.500000    2.265550   30.272590    0.447368    0.392344   35.627188\nstd     120.810458    0.841838   14.181209    0.896760    0.981429   55.907576\nmin     892.000000    1.000000    0.170000    0.000000    0.000000    0.000000\n25%     996.250000    1.000000   21.000000    0.000000    0.000000    7.895800\n50%    1100.500000    3.000000   27.000000    0.000000    0.000000   14.454200\n75%    1204.750000    3.000000   39.000000    1.000000    0.000000   31.500000\nmax    1309.000000    3.000000   76.000000    8.000000    9.000000  512.329200\n"
    }
   ],
   "source": [
    "train_data = pd.read_csv(r'E:\\bi_course\\biCourse\\L3\\sat_course\\train.csv')\n",
    "test_data =  pd.read_csv(r'E:\\bi_course\\biCourse\\L3\\sat_course\\test.csv')\n",
    "\n",
    "#数据探索\n",
    "print('训练数据行列数:',train_data.shape, '; 测试数据行列数:',test_data.shape)\n",
    "\n",
    "print('-'*20,'训练集数据探索','-'*20)\n",
    "train_data.info()\n",
    "print('-'*40,'-'*40)\n",
    "print(train_data.describe())\n",
    "\n",
    "print('-'*20,'测试集数据探索','-'*20)\n",
    "test_data.info()\n",
    "print('-'*40,'-'*40)\n",
    "print(test_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取title\n",
    "def extract_title(name: str):\n",
    "    title = name.split(', ')[1].split('.')[0]\n",
    "    return title\n",
    "\n",
    "#将titel分为四类: 'Mr','Ms','Miss','Honored'\n",
    "def unify_title(title: str):\n",
    "\n",
    "    if title in ['Dr','Rev','Major','Col','Lady','Jonkheer','Sir','the Countess','Capt','Don','Dona']: \n",
    "        return  'Honored'\n",
    "    elif title in ['Mlle','Ms']:\n",
    "        return 'Miss'\n",
    "    elif title == 'Mme':\n",
    "        return  'Mrs'\n",
    "    elif title == 'Master': #不确定master是否应该分为mr\n",
    "        return  'Mr'\n",
    "    else :\n",
    "        return title\n",
    "\n",
    "#用某一列(groupCol)的分类平均值计算填充的缺失值\n",
    "def fillna_usingMean(df,groupCol, naCol):\n",
    "    groupList = list(set(df[groupCol]))\n",
    "    df_filled_na = pd.DataFrame()\n",
    "    for group in groupList:\n",
    "        df_select = df [df[groupCol] == group]\n",
    "        df_select[naCol].fillna(df_select[naCol].mean(), inplace = True)\n",
    "        df_filled_na = df_filled_na.append(df_select)\n",
    "\n",
    "    df = df_filled_na\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "#训练不同模型并输出分数报告\n",
    "def get_model_score(clf, X_train, y_train, X_test, y_test):\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predit = clf.predict(X_test)\n",
    "\n",
    "    # 模型表现\n",
    "    report = pd.Series()\n",
    "    report['clfName'] = str(clf).split('(')[0]\n",
    "    report['score']  = round(clf.score(X_train, y_train), 4)\n",
    "    report['cv_score'] = round(np.mean(cross_val_score(clf, X_train, y_train, cv=10)),4)\n",
    "    report['auc_score'] = round(roc_auc_score(y_test, y_predit),4)\n",
    "    report['clf'] = clf\n",
    "    report = pd.DataFrame(report).T\n",
    "\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "数据处理后特征缺失值总数:0\n"
    }
   ],
   "source": [
    "#数据预处理 \n",
    "\n",
    "#整合train & test, 对数据进行预处理\n",
    "train_data['type'] = 'train'\n",
    "test_data['type'] = 'test'\n",
    "df = pd.concat([train_data, test_data], axis = 0)\n",
    "\n",
    "\n",
    "#需要处理的字段: Name(姓名Title混合), age(缺失),Cabin(缺失),Embarked(缺失)\n",
    "#家庭人数: 配偶, 子女, 亲属 计算登船家庭成员数\n",
    "\n",
    "df['newTitle']= df['Name'].apply(lambda x: unify_title(extract_title(x))) #提取title ; 姓和名不统一, 暂时不使用该字段作为特征\n",
    "\n",
    "#fillna\n",
    "df = fillna_usingMean(df,'newTitle', 'Age')  #用对应title的平均值进行age填充:\n",
    "df = fillna_usingMean(df,'Pclass', 'Fare') #用对应Pclass的平均值进行fare填充\n",
    "\n",
    "#drop掉缺失严重的Cabin, Name两列, drop掉有两个缺失值的Embarked所在行\n",
    "df = df.drop(columns={'Cabin','Name'}).dropna(subset=['Embarked'])\n",
    "\n",
    "#新增衍生特征\n",
    "df['familyNum'] = df['Parch'] + df['SibSp'] + 1 #包含本人的家庭成员数\n",
    "\n",
    "ticket_groupby = df.groupby('Ticket', as_index = False)['PassengerId'].count().rename(columns = {'PassengerId':'PassNumWithSameTicket'})\n",
    "df = df.merge(ticket_groupby, on = 'Ticket')  #同一个ticket的人数\n",
    "\n",
    "\n",
    "df['age_mp_Fare'] = df['Age'] * df['Fare']\n",
    "df['age_mp_Pclass'] = df['Age'] * df['Pclass']\n",
    "\n",
    "print('数据处理后特征缺失值总数:',sum(df.drop(columns ='Survived').isna().sum())) #排除Survived列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            Age Embarked      Fare  Parch  PassengerId  Pclass     Sex  SibSp  \\\n0     58.000000        S   26.5500      0           12       1  female      0   \n1     23.000000        S  263.0000      2           89       1  female      3   \n2     24.000000        S  263.0000      2          342       1  female      3   \n3     28.000000        S  263.0000      2          945       1  female      3   \n4     60.000000        S  263.0000      4          961       1  female      1   \n...         ...      ...       ...    ...          ...     ...     ...    ...   \n1302  22.000000        S    7.7750      0         1290       3    male      0   \n1303  31.000000        Q    7.7333      0         1291       3    male      0   \n1304  30.014322        S    8.0500      0         1305       3    male      0   \n1305  38.500000        S    7.2500      0         1307       3    male      0   \n1306  30.014322        S    8.0500      0         1308       3    male      0   \n\n      Survived              Ticket   type newTitle  familyNum  \\\n0          1.0              113783  train     Miss          1   \n1          1.0               19950  train     Miss          6   \n2          1.0               19950  train     Miss          6   \n3          NaN               19950   test     Miss          6   \n4          NaN               19950   test      Mrs          6   \n...        ...                 ...    ...      ...        ...   \n1302       NaN              347065   test       Mr          1   \n1303       NaN               21332   test       Mr          1   \n1304       NaN           A.5. 3236   test       Mr          1   \n1305       NaN  SOTON/O.Q. 3101262   test       Mr          1   \n1306       NaN              359309   test       Mr          1   \n\n      PassNumWithSameTicket  age_mp_Fare  age_mp_Pclass  \n0                         1   1539.90000      58.000000  \n1                         6   6049.00000      23.000000  \n2                         6   6312.00000      24.000000  \n3                         6   7364.00000      28.000000  \n4                         6  15780.00000      60.000000  \n...                     ...          ...            ...  \n1302                      1    171.05000      66.000000  \n1303                      1    239.73230      93.000000  \n1304                      1    241.61529      90.042965  \n1305                      1    279.12500     115.500000  \n1306                      1    241.61529      90.042965  \n\n[1307 rows x 16 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Embarked</th>\n      <th>Fare</th>\n      <th>Parch</th>\n      <th>PassengerId</th>\n      <th>Pclass</th>\n      <th>Sex</th>\n      <th>SibSp</th>\n      <th>Survived</th>\n      <th>Ticket</th>\n      <th>type</th>\n      <th>newTitle</th>\n      <th>familyNum</th>\n      <th>PassNumWithSameTicket</th>\n      <th>age_mp_Fare</th>\n      <th>age_mp_Pclass</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>58.000000</td>\n      <td>S</td>\n      <td>26.5500</td>\n      <td>0</td>\n      <td>12</td>\n      <td>1</td>\n      <td>female</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>113783</td>\n      <td>train</td>\n      <td>Miss</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1539.90000</td>\n      <td>58.000000</td>\n    </tr>\n    <tr>\n      <td>1</td>\n      <td>23.000000</td>\n      <td>S</td>\n      <td>263.0000</td>\n      <td>2</td>\n      <td>89</td>\n      <td>1</td>\n      <td>female</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>19950</td>\n      <td>train</td>\n      <td>Miss</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6049.00000</td>\n      <td>23.000000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>24.000000</td>\n      <td>S</td>\n      <td>263.0000</td>\n      <td>2</td>\n      <td>342</td>\n      <td>1</td>\n      <td>female</td>\n      <td>3</td>\n      <td>1.0</td>\n      <td>19950</td>\n      <td>train</td>\n      <td>Miss</td>\n      <td>6</td>\n      <td>6</td>\n      <td>6312.00000</td>\n      <td>24.000000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>28.000000</td>\n      <td>S</td>\n      <td>263.0000</td>\n      <td>2</td>\n      <td>945</td>\n      <td>1</td>\n      <td>female</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>19950</td>\n      <td>test</td>\n      <td>Miss</td>\n      <td>6</td>\n      <td>6</td>\n      <td>7364.00000</td>\n      <td>28.000000</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>60.000000</td>\n      <td>S</td>\n      <td>263.0000</td>\n      <td>4</td>\n      <td>961</td>\n      <td>1</td>\n      <td>female</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>19950</td>\n      <td>test</td>\n      <td>Mrs</td>\n      <td>6</td>\n      <td>6</td>\n      <td>15780.00000</td>\n      <td>60.000000</td>\n    </tr>\n    <tr>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <td>1302</td>\n      <td>22.000000</td>\n      <td>S</td>\n      <td>7.7750</td>\n      <td>0</td>\n      <td>1290</td>\n      <td>3</td>\n      <td>male</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>347065</td>\n      <td>test</td>\n      <td>Mr</td>\n      <td>1</td>\n      <td>1</td>\n      <td>171.05000</td>\n      <td>66.000000</td>\n    </tr>\n    <tr>\n      <td>1303</td>\n      <td>31.000000</td>\n      <td>Q</td>\n      <td>7.7333</td>\n      <td>0</td>\n      <td>1291</td>\n      <td>3</td>\n      <td>male</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>21332</td>\n      <td>test</td>\n      <td>Mr</td>\n      <td>1</td>\n      <td>1</td>\n      <td>239.73230</td>\n      <td>93.000000</td>\n    </tr>\n    <tr>\n      <td>1304</td>\n      <td>30.014322</td>\n      <td>S</td>\n      <td>8.0500</td>\n      <td>0</td>\n      <td>1305</td>\n      <td>3</td>\n      <td>male</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>A.5. 3236</td>\n      <td>test</td>\n      <td>Mr</td>\n      <td>1</td>\n      <td>1</td>\n      <td>241.61529</td>\n      <td>90.042965</td>\n    </tr>\n    <tr>\n      <td>1305</td>\n      <td>38.500000</td>\n      <td>S</td>\n      <td>7.2500</td>\n      <td>0</td>\n      <td>1307</td>\n      <td>3</td>\n      <td>male</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>SOTON/O.Q. 3101262</td>\n      <td>test</td>\n      <td>Mr</td>\n      <td>1</td>\n      <td>1</td>\n      <td>279.12500</td>\n      <td>115.500000</td>\n    </tr>\n    <tr>\n      <td>1306</td>\n      <td>30.014322</td>\n      <td>S</td>\n      <td>8.0500</td>\n      <td>0</td>\n      <td>1308</td>\n      <td>3</td>\n      <td>male</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>359309</td>\n      <td>test</td>\n      <td>Mr</td>\n      <td>1</td>\n      <td>1</td>\n      <td>241.61529</td>\n      <td>90.042965</td>\n    </tr>\n  </tbody>\n</table>\n<p>1307 rows × 16 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                      clfName   score cv_score auc_score  \\\n0  LinearDiscriminantAnalysis   0.791   0.7701    0.8321   \n0          LogisticRegression  0.7974   0.7974    0.8261   \n0                         SVC  0.7701   0.7668    0.8181   \n0               MultinomialNB  0.7717   0.7701    0.8171   \n0        KNeighborsClassifier  0.8424   0.7798    0.8161   \n0                 BernoulliNB  0.7701   0.7685    0.8091   \n0  GradientBoostingClassifier  0.9228   0.7974    0.7931   \n0                  GaussianNB  0.7717   0.7716    0.7892   \n0          AdaBoostClassifier  0.8521   0.7942    0.7721   \n0        ExtraTreesClassifier  0.9904   0.7734    0.7701   \n0      RandomForestClassifier  0.9759   0.7879    0.7411   \n0               XGBClassifier  0.9887   0.7862    0.7321   \n0      DecisionTreeClassifier  0.9904   0.7251    0.7002   \n\n                                                 clf  \n0  LinearDiscriminantAnalysis(n_components=None, ...  \n0  LogisticRegression(C=1.0, class_weight=None, d...  \n0  SVC(C=1.0, cache_size=200, class_weight=None, ...  \n0  MultinomialNB(alpha=1.0, class_prior=None, fit...  \n0  KNeighborsClassifier(algorithm='auto', leaf_si...  \n0  BernoulliNB(alpha=1.0, binarize=0.0, class_pri...  \n0  ([DecisionTreeRegressor(criterion='friedman_ms...  \n0       GaussianNB(priors=None, var_smoothing=1e-09)  \n0  (DecisionTreeClassifier(class_weight=None, cri...  \n0  (ExtraTreeClassifier(class_weight=None, criter...  \n0  (DecisionTreeClassifier(class_weight=None, cri...  \n0  XGBClassifier(base_score=0.5, booster='gbtree'...  \n0  DecisionTreeClassifier(class_weight=None, crit...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clfName</th>\n      <th>score</th>\n      <th>cv_score</th>\n      <th>auc_score</th>\n      <th>clf</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>0</td>\n      <td>LinearDiscriminantAnalysis</td>\n      <td>0.791</td>\n      <td>0.7701</td>\n      <td>0.8321</td>\n      <td>LinearDiscriminantAnalysis(n_components=None, ...</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>LogisticRegression</td>\n      <td>0.7974</td>\n      <td>0.7974</td>\n      <td>0.8261</td>\n      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>SVC</td>\n      <td>0.7701</td>\n      <td>0.7668</td>\n      <td>0.8181</td>\n      <td>SVC(C=1.0, cache_size=200, class_weight=None, ...</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>MultinomialNB</td>\n      <td>0.7717</td>\n      <td>0.7701</td>\n      <td>0.8171</td>\n      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>KNeighborsClassifier</td>\n      <td>0.8424</td>\n      <td>0.7798</td>\n      <td>0.8161</td>\n      <td>KNeighborsClassifier(algorithm='auto', leaf_si...</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>BernoulliNB</td>\n      <td>0.7701</td>\n      <td>0.7685</td>\n      <td>0.8091</td>\n      <td>BernoulliNB(alpha=1.0, binarize=0.0, class_pri...</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>GradientBoostingClassifier</td>\n      <td>0.9228</td>\n      <td>0.7974</td>\n      <td>0.7931</td>\n      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>GaussianNB</td>\n      <td>0.7717</td>\n      <td>0.7716</td>\n      <td>0.7892</td>\n      <td>GaussianNB(priors=None, var_smoothing=1e-09)</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>AdaBoostClassifier</td>\n      <td>0.8521</td>\n      <td>0.7942</td>\n      <td>0.7721</td>\n      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>ExtraTreesClassifier</td>\n      <td>0.9904</td>\n      <td>0.7734</td>\n      <td>0.7701</td>\n      <td>(ExtraTreeClassifier(class_weight=None, criter...</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>RandomForestClassifier</td>\n      <td>0.9759</td>\n      <td>0.7879</td>\n      <td>0.7411</td>\n      <td>(DecisionTreeClassifier(class_weight=None, cri...</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>XGBClassifier</td>\n      <td>0.9887</td>\n      <td>0.7862</td>\n      <td>0.7321</td>\n      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n    </tr>\n    <tr>\n      <td>0</td>\n      <td>DecisionTreeClassifier</td>\n      <td>0.9904</td>\n      <td>0.7251</td>\n      <td>0.7002</td>\n      <td>DecisionTreeClassifier(class_weight=None, crit...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "#模型数据准备\n",
    "\n",
    "#创建x_train, y_train, x_test\n",
    "\n",
    "df_toTrain = df[df['type'] == 'train']\n",
    "df_toPredict = df[df['type'] == 'test'] #训练模型后预测\n",
    "\n",
    "features = ['Age', 'Embarked','Fare','Pclass','Sex','SibSp','newTitle','familyNum','PassNumWithSameTicket','age_mp_Fare']\n",
    "\n",
    "X_train,X_test, y_train,y_test = train_test_split(df_toTrain[features], df_toTrain['Survived'], train_size = 0.7, random_state =1)   #模型训练集和测试集\n",
    "x_toPredict = df_toPredict[features] #样本外需要预测的数据\n",
    "\n",
    "#转化成oneHot Coding\n",
    "X_train = pd.get_dummies(X_train) \n",
    "X_test = pd.get_dummies(X_test)\n",
    "x_toPredict = pd.get_dummies(x_toPredict) \n",
    "\n",
    "#数据规范化\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "x_toPredict = scaler.fit_transform(x_toPredict)\n",
    "\n",
    "#训练不同模型并得到评估结果\n",
    "\n",
    "clfList = [DecisionTreeClassifier(), LogisticRegression(), GaussianNB(),MultinomialNB(),BernoulliNB(),svm.SVC(), ExtraTreesClassifier(),\\\n",
    "            RandomForestClassifier(), KNeighborsClassifier(), AdaBoostClassifier(),GradientBoostingClassifier(), XGBClassifier(), LinearDiscriminantAnalysis(),]\n",
    "\n",
    "score_report = pd.DataFrame()\n",
    "\n",
    "for clf in clfList:\n",
    "\n",
    "    result = get_model_score(clf, X_train, y_train, X_test, y_test)\n",
    "    score_report = score_report.append(result)\n",
    "\n",
    "# score_report\n",
    "score_report = score_report.sort_values(by = 'auc_score', ascending = False)\n",
    "score_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "bestModel: RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=2,\n                       min_weight_fraction_leaf=0.0, n_estimators=10,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)\nsubmission to csv done\n"
    }
   ],
   "source": [
    "#拿最优模型预测df_toPredict(即test数据集)\n",
    "\n",
    "bestModel = score_report.iloc[0]['clf']\n",
    "bestModel.fit(X_train, y_train)\n",
    "\n",
    "print('bestModel:', bestModel)\n",
    "\n",
    "sumbmission = pd.DataFrame()\n",
    "sumbmission['PassengerId'] = df_toPredict['PassengerId']\n",
    "sumbmission['Survived'] = bestModel.predict(x_toPredict).astype(int) #用最优模型对y值进行预测\n",
    "sumbmission = sumbmission.set_index('PassengerId').sort_index()\n",
    "\n",
    "sumbmission.to_csv('zoni_submission.csv', header = True)\n",
    "\n",
    "print('submission to csv done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Optimization Progress:  18%|█▊        | 59/330 [00:31<02:49,  1.59pipeline/s]Generation 1 - Current best internal CV score: 0.8247741935483871\nOptimization Progress:  27%|██▋       | 90/330 [00:44<02:04,  1.93pipeline/s]Generation 2 - Current best internal CV score: 0.8248387096774193\nOptimization Progress:  36%|███▌      | 119/330 [01:04<03:47,  1.08s/pipeline]Generation 3 - Current best internal CV score: 0.8248387096774193\nOptimization Progress:  45%|████▌     | 150/330 [01:26<03:59,  1.33s/pipeline]Generation 4 - Current best internal CV score: 0.8248387096774193\nOptimization Progress:  55%|█████▍    | 180/330 [01:44<02:19,  1.08pipeline/s]Generation 5 - Current best internal CV score: 0.8248387096774193\nOptimization Progress:  64%|██████▎   | 210/330 [02:22<01:34,  1.27pipeline/s]Generation 6 - Current best internal CV score: 0.8279870967741936\nOptimization Progress:  73%|███████▎  | 240/330 [02:42<00:57,  1.56pipeline/s]Generation 7 - Current best internal CV score: 0.8279870967741936\nOptimization Progress:  82%|████████▏ | 270/330 [03:10<00:49,  1.21pipeline/s]Generation 8 - Current best internal CV score: 0.8295741935483869\nOptimization Progress:  91%|█████████ | 300/330 [03:35<00:24,  1.21pipeline/s]Generation 9 - Current best internal CV score: 0.8295741935483869\nOptimization Progress: 100%|██████████| 330/330 [03:59<00:00,  1.87pipeline/s]Generation 10 - Current best internal CV score: 0.8295741935483869\nOptimization Progress: 100%|██████████| 330/330 [03:59<00:00,  1.87pipeline/s]\nBest pipeline:GradientBoostingClassifier(input_matrix, learning_rate=0.1, max_depth=4, max_features=0.7000000000000001, min_samples_leaf=5, min_samples_split=16, n_estimators=100, subsample=0.3)\n0.797752808988764\n"
    }
   ],
   "source": [
    "#使用TPOT 选择最优模型\n",
    "from tpot import TPOTClassifier\n",
    "\n",
    "tpot = TPOTClassifier( generations  = 10, population_size = 30, verbosity = 2)\n",
    "tpot.fit(X_train, y_train)\n",
    "\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('tpot_titanic_pipeline.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}